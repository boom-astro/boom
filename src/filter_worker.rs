
use std::{sync::{mpsc, Arc, Mutex}, error::Error, collections::HashMap};
use redis::AsyncCommands;
use crate::{conf, filter, worker_util::WorkerCmd, worker_util};
use redis::streams::StreamReadOptions;

// filter worker as a standalone function run by the scheduler
#[tokio::main]
pub async fn filter_worker(
    id: String,
    receiver: Arc<Mutex<mpsc::Receiver<WorkerCmd>>>,
    stream_name: String,
    config_path: String,
) -> Result<(), Box<dyn Error>> {

    let catalog = stream_name.clone();
    let filters = vec![3];
    let mut filter_ids: Vec<i32> = Vec::new();

    for i in 0..filters.len() {
        if !filter_ids.contains(&filters[i]) {
            filter_ids.push(filters[i]);
        }
    }
    println!("Starting filter worker for {} with filters {:?}", catalog, filter_ids);

    // connect to mongo and redis
    let config_file = conf::load_config(&config_path).unwrap();
    let db = conf::build_db(&config_file).await;
    let client_redis = redis::Client::open(
        "redis://localhost:6379".to_string()).unwrap();
    let mut con = client_redis
        .get_multiplexed_async_connection().await.unwrap();

    let mut alert_counter = 0;
    let command_interval = worker_util::get_check_command_interval(config_file, &stream_name);
    
    // build filters and organize by permission level
    let mut filter_table: HashMap<i64, Vec<filter::Filter>> = HashMap::new();
    for id in filter_ids.clone() {
        let filter = filter::Filter::build(id, &db).await;
        match filter {
            Ok(filter) => {
                let perms = filter.permissions.iter().max().unwrap();
                if !filter_table.contains_key(perms) {
                    filter_table.insert(perms.clone(), Vec::new());
                }
                filter_table.entry(perms.clone()).and_modify(|filters| filters.push(filter));
            },
            Err(e) => {
                println!("got error when trying to build filter {}: {}", id, e);
                return Err(e);
            }
        }
    }

    // initialize redis streams based on permission levels
    let mut redis_streams = HashMap::new();
    for filter_vec in filter_table.values() {
        for filter in filter_vec {
            let perms = filter.permissions.iter().max().unwrap();
            let stream = format!("{stream}_programid_{programid}_filter_stream",
                stream = filter.catalog, programid = perms);
            if !redis_streams.contains_key(perms) {
                redis_streams.insert(perms.clone(), stream);
            }
        }
    }

    // create consumer groups, read_options, and output queues for each filter
    let mut read_options = HashMap::new();
    let mut filter_results_queues: HashMap<i32, String> = HashMap::new();
    for filter_vec in filter_table.values() {
        for filter in filter_vec {
            let consumer_group = format!("filter_{filter_id}_group", filter_id = filter.id);
            let consumer_group_res: Result<(), redis::RedisError> = con.xgroup_create(
                &redis_streams[filter.permissions.iter().max().unwrap()], 
                &consumer_group, "0").await;
            match consumer_group_res {
                Ok(()) => {
                    println!("Created consumer group for filter {}", filter.id);
                },
                Err(e) => {
                    println!("Consumer group already exists for filter {}: {:?}", filter.id, e);
                }
            }
            let opts = StreamReadOptions::default()
                .group(consumer_group, "worker_1")
                .count(100);
            read_options.insert(filter.id, opts);
            filter_results_queues.insert(
                filter.id, 
                format!("filter_{filter_id}_results", filter_id = filter.id));
        }
    }

    // keep track of how many streams are empty in order to take breaks
    let mut empty_stream_counter: usize = 0;

    loop {
        // check for command from threadpool
        if alert_counter - command_interval > 0 {
            alert_counter = 0;
            if let Ok(command) = receiver.lock().unwrap().try_recv() {
                match command {
                    WorkerCmd::TERM => {
                        println!("alert worker {} received termination command", id);
                        return Ok(());
                    },
                }
            }
        }
        
        for (perm, filters) in &mut filter_table {
            for filter in filters {
                let candids = worker_util::get_candids_from_stream(
                    &mut con,
                    &redis_streams[&perm],
                    &read_options[&filter.id]).await;
                if candids.len() == 0 {
                    empty_stream_counter += 1;
                    continue;
                }
                let in_count = candids.len();
                alert_counter += in_count as i64;

                println!("got {} candids from redis stream for filter {}", in_count, redis_streams[&perm]);
                println!("running filter with id {} on {} alerts", filter.id, in_count);

                let start = std::time::Instant::now();

                let out_documents = filter.run(candids, &db).await.unwrap();
                if out_documents.len() == 0 {
                    continue;
                }
                // convert the documents to a format that any other worker (even in python) can read
                // for that we can deserialize the Document to json
                let out_documents: Vec<String> = out_documents.iter().map(|doc| {
                    let json = serde_json::to_string(doc).unwrap();
                    json
                }).collect();
                con.lpush::<&str, &Vec<String>, isize>(
                    &filter_results_queues[&filter.id],
                    &out_documents).await.unwrap();

                println!(
                    "{}/{} alerts passed filter {} in {}s", 
                    out_documents.len(), in_count, filter.id, start.elapsed().as_secs_f64());
            }
        }
        if empty_stream_counter == filter_ids.len() {
            println!("FILTER WORKER {}: All streams empty", id);
            tokio::time::sleep(tokio::time::Duration::from_secs(5)).await;
            alert_counter = 0;
            if let Ok(command) = receiver.lock().unwrap().try_recv() {
                match command {
                    WorkerCmd::TERM => {
                        println!("alert worker {} received termination command", id);
                        return Ok(());
                    },
                }
            }
        }
        empty_stream_counter = 0;
    }
}